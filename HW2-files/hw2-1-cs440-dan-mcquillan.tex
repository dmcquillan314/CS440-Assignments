\input{cs440_style.tex}
\usepackage{algorithm}
\usepackage{listings}
%\usepackage{algpseudocode}
\usepackage{graphicx,amssymb,amsmath}
\usepackage{epstopdf}
\usepackage{color}
\usepackage{listings}
\lstset{ %
language=Java,                % choose the language of the code
basicstyle=\footnotesize,       % the size of the fonts that are used for the code
numbers=left,                   % where to put the line-numbers
numberstyle=\footnotesize,      % the size of the fonts that are used for the line-numbers
stepnumber=1,                   % the step between two line-numbers. If it is 1 each line will be numbered
numbersep=5pt,                  % how far the line-numbers are from the code
backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
showspaces=false,               % show spaces adding particular underscores
showstringspaces=false,         % underline spaces within strings
showtabs=false,                 % show tabs within strings adding particular underscores
frame=single,           % adds a frame around the code
tabsize=2,          % sets default tabsize to 2 spaces
captionpos=b,           % sets the caption-position to bottom
breaklines=true,        % sets automatic line breaking
breakatwhitespace=false,    % sets if automatic breaks should only happen at whitespace
escapeinside={\%*}{*)}          % if you want to add a comment within your code
}

\sloppy


\oddsidemargin 0in
\evensidemargin 0in
\textwidth 6.5in
\topmargin -0.5in
\textheight 9.0in

\begin{document}

\solution{Dan McQuillan}{\today}{2 - Part 1}{Spring 2014}

\pagestyle{myheadings}  % Leave this command alone

\begin{enumerate}

	\item {\bf Solution to problem 1}
	
		\begin{enumerate}
			\item{\bf Training on data set 1}
				\begin{enumerate}
					\item[a)] The final weights \\ \\
						\(Starting Threshhold = 0.0\) \\
						\(Calculated Threshhold = -53.5\) \\ \\
						\bf Weights: \\
						\( w_{1} \rightarrow -752.0 \) \\
						\( w_{2} \rightarrow 4771.0 \) \\
						\( w_{3} \rightarrow 17714.0 \) \\
						\( w_{4} \rightarrow 762.0 \) \\
						\( w_{5} \rightarrow 6.0 \) \\
						\( w_{6} \rightarrow 676.0 \) \\
						\( w_{7} \rightarrow 3060.0 \) \\
						\( w_{8} \rightarrow -2004.0 \) \\
						\( w_{9} \rightarrow 5459.0 \) \\
						\( w_{10} \rightarrow 9591.2999999989 \) \\
						\( w_{11} \rightarrow 3832.0 \) \\
						\( w_{12} \rightarrow 14963.0 \) \\
						\( w_{13} \rightarrow 20912.0 \) \\
						
					\item[b)] The number of training epochs required \\
						\textnormal{The training took 1979 epochs.} \\
					
					\item[c)] The margin \\
						\( \gamma \rightarrow 0.1521547389026288 \)
				\end{enumerate}
			\item{\bf Test on data set 1}
				\begin{enumerate}
					\item[a)] A confusion matrix \\
						\( 
							\begin{array}{|c|c|}
								\hline
								54 & 0 \\
								\hline
								0 & 63 \\
								\hline
							\end{array} 
						\) \\
					\item[b)] Two lists of example indices \\ 
						No errors were found with this dataset since the weight vectors were calculated from this dataset. \\
					\item[c)] The total loss summed over the misclassified examples \\
						The loss for this dataset is 0.0 since it is the training data set.					\\
				\end{enumerate}
			\item{\bf Test on data set 2}
				\begin{enumerate}
					\item[a)] A confusion matrix \\
						\( 
							\begin{array}{|c|c|}
								\hline
								12 & 1 \\
								\hline
								0 & 20 \\
								\hline
							\end{array} 
						\) \\
					\item[b)] Two lists of example indices \\
						\bf{False Negatives:} \\
						\textnormal{Index: 22} \\
						\textnormal{Inputs:} \( (60.0, 1.0, 4.0, 140.0, 293.0, 0.0, 2.0, 170.0, 0.0, 1.2, 2.0, 2.0, 7.0) \) \\ \\
						\bf{False Positives:} \\
						\textnormal{There were no false positives} \\
					\item[c)] The total loss summed over the misclassified examples \\
					\textnormal{Total loss:} \( 77.440000001312 \)
				\end{enumerate}
			\item{\bf Application to data set 3} \\
				\bf{Classifications: } \\
				\( 1 \rightarrow 0.0 \) \\
				\( 2 \rightarrow 1.0 \) \\
				\( 3 \rightarrow 0.0 \) \\
				\( 4 \rightarrow 1.0 \) \\
				\( 5 \rightarrow 1.0 \) \\
				\( 6 \rightarrow 0.0 \) \\
				\( 7 \rightarrow 0.0 \) \\
				\( 8 \rightarrow 0.0 \) \\
				\( 9 \rightarrow 0.0 \) \\
				\( 10 \rightarrow 1.0 \) \\
				\( 11 \rightarrow 1.0 \) \\
				\( 12 \rightarrow 0.0 \) \\
				\( 13 \rightarrow 1.0 \) \\
				\( 14 \rightarrow 0.0 \) \\
				\( 15 \rightarrow 0.0 \) \\
				\( 16 \rightarrow 0.0 \) \\
				\( 17 \rightarrow 1.0 \) \\
				\( 18 \rightarrow 0.0 \) \\
				\( 19 \rightarrow 0.0 \) \\
				\( 20 \rightarrow 0.0 \) \\
				\( 21 \rightarrow 0.0 \) \\
				
				\bf{Which feature is the most important?} \\
				\textnormal{In order to determine the most influential property I have used the correlation coefficients to find the most correlation between each property and the classification.  The source code to find this property is also within the project.} \\ \\
				\( \begin{array}{l|l}
					\bf{Label} & \bf{Correlation Coefficient} \\
					\hline
					\text{ age } & 0.576399638726158 \\
					\text{ sex } & 0.15811388300841894 \\
					\text{ chest } & 0.4934637712198269 \\
					\text{ resting blood pressure } & 0.08008953852726183 \\
					\text{ serum cholestoral } & -0.32382553481251514 \\
					\text{ fasting blood sugar } & 0.31622776601683766 \\
					\text{ resting electrocardiographic results } & 0.1386750490563073 \\
					\text{ maximum heart rate achieved } & -0.5353426981014223 \\
					\text{ exercise induced angina } & 0.685994340570035 \\
					\text{ oldpeak } & 0.8086701966434094 \\
					\text{ slope } & 0.6123724356957945 \\
					\text{ number of major vessels } & 0.8152133857595864 \\
					\text{ thal } & 0.43905703995876144 \\
				\end{array} \) \\ \\
				
				\bf{ Property With Maximum Correlation} \\ 
				Label:  \textnormal{number of major vessels} \\
				Correlation Coefficient: \(0.8152133857595864\)
		\end{enumerate}

\end{enumerate}

\section{ Source Code }
The following is the source code for the assignment.  It consists of 5 classes to get all the required output. 
\begin{itemize}
	\item CorrelationCoefficient \\
		This class is used to calculate the correlation coefficient on the resultant classifications when running the learner in application mode to tell which is the most important input.
	\item Pair \\
		This is mainly a utility class used to group the weight and input together for clarity in traversal of the arrays.
	\item VectorUtils \\
		This is a collection of vector utilities that are used throughout the application such as: dot product, addition, scaling, finding the norm, and zipping two vectors into one array of Pairs.  This is used to traverse the arrays in parallel.
	\item WidrowHoffLearner \\
		This class has the Widrow Hoff Learning specific code as defined in the assignment and lectures.
	\item Main \\
		This class simply runs all the classes and displays the output. \\
		
		I have excluded the source for DataSet for brevity.
\end{itemize}
\subsection{ Main.java }
\begin{lstlisting}
package hw2.widrowhoff;

import java.util.List;

public class Main {

	@SuppressWarnings("unused")
	public static void main(String[] args) {
		final String dataSet1Csv = "DataSet1.csv";
		final String dataSet2Csv = "DataSet2.csv";
		final String dataSet3Csv = "DataSet3.csv";
		
		DataSet dataSet1 = new DataSet(dataSet1Csv);
		DataSet dataSet2 = new DataSet(dataSet2Csv);
		DataSet dataSet3 = new DataSet(dataSet3Csv);
		
		WidrowHoffLearner learner = new WidrowHoffLearner( dataSet1, 0.0 );
		learner.trainWeightVector();
		
		for( int i = 0; i < learner.getWeights().length; i++ ) {
			System.out.println("\\( w_{" + (i+1) + "} \\rightarrow " + learner.getWeights()[i] + " \\)");
		}
		
		System.out.println("------------------------");
		System.out.println("Data set 1 test");
		System.out.println("------------------------");
		learner.testWeightVector(dataSet1);
		System.out.println("------------------------");
		System.out.println("Data set 2 test");
		System.out.println("------------------------");
		learner.testWeightVector(dataSet2);
		
		System.out.println("------------------------");
		System.out.println("Data set 3 application");
		System.out.println("------------------------");
		
		final List<Double> classifications = learner.applyWeightVector(dataSet3);
		for( int i = 0; i < classifications.size(); i++ ) {
			System.out.println( "\\( " + (i+1) + " \\rightarrow " + classifications.get(i) + " \\) \\\\" );
		}
		
		final List<Pair<String,Double>> coefficients = CorrelationCoefficient.calculate(dataSet3, classifications);
		System.out.println("------------------------");
		System.out.println("Correlation Coefficients");
		System.out.println("------------------------");
		String maxProp = "";
		Double maxCorrelation = Double.MIN_VALUE;
		System.out.println("\\( \\begin{array}{l|l}");
		System.out.println("\\bf{Label} & \\bf{Correlation Coefficient} \\\\");
		System.out.println("\\hline");
		for(final Pair<String, Double> coefficient : coefficients ) {
			System.out.println("\\text{ " + coefficient.getLeft().trim().replaceAll("[^A-Za-z0-9]", " ") + " } & " + coefficient.getRight() + " \\\\");
			if( coefficient.getRight().compareTo(maxCorrelation) > 0 ) {
				maxProp = coefficient.getLeft();
				maxCorrelation = coefficient.getRight();
			}
		}
		System.out.println("\\end{array} \\)");
		System.out.println();

		
		System.out.println("------------------------");
		System.out.println("Maximum Correlation Prop");
		System.out.println("------------------------");
		System.out.println("\\bf{ Property With Maximum Correlation} \\\\ ");
		System.out.println("Label: " + maxProp.replaceAll("[^A-Za-z0-9]", " ") + " \\\\");
		System.out.println("Correlation Coefficient: \\(" + maxCorrelation + "\\)");
	}

}
\end{lstlisting}

\subsection{Pair.java}
\begin{lstlisting}
package hw2.widrowhoff;

public class Pair<T1, T2> {
	private final T1 left;
	private final T2 right;
	
	public Pair(T1 left, T2 right) {
		this.left = left;
		this.right = right;
	}
	
	public T1 getLeft() {
		return left;
	}
	public T2 getRight() {
		return right;
	}
}
\end{lstlisting}

\subsection{VectorUtils.java}
\begin{lstlisting}
package hw2.widrowhoff;

import java.util.ArrayList;
import java.util.List;

public class VectorUtils {
	
	public static double dotProduct( final double[] x, final double[] y ) {
		double sum = 0;
		for( int i = 0; i < x.length && i < y.length; i++ ) {
			sum += x[i] * y[i];
		}
		
		return sum;
	}
	
	public static double[] scale( final double[] x, final double scalar ) {
		double[] xCopy = x.clone();
		for( int i = 0; i < x.length; i++ ) {
			xCopy[i] *= scalar;
		}
		return xCopy;
	}
	
	public static double[] add( double[] x, final double[] y ) {
		double[] xCopy = x.clone();
		double[] yCopy = y.clone();
		for( int i = 0; i < xCopy.length && i < yCopy.length; i++ ) {
			xCopy[i] += yCopy[i];
		}
		
		return xCopy;
	}
	
	public static List<Pair<Double, Double> > zip( double[] x, double[] y ) {
		List<Pair<Double, Double> > zippedVector = new ArrayList<Pair<Double, Double>>();
		for( int i = 0; i < x.length && i < y.length; i++ ) {
			zippedVector.add( new Pair<Double,Double>(x[i], y[i]) );
		}
		return zippedVector;
	}
	
	public static double[] unitVector( double[] x ) {
		double[] copy = x.clone();
		double norm = norm(copy);
		return scale(x, 1.0 / norm );
	}
	
	public static double norm( double[] x ) {
		double sum = 0;
		for( int i = 0; i < x.length; i++) {
			sum += Math.pow(x[i], 2.0);
		}
		return Math.sqrt(sum);
	}
}
\end{lstlisting}
\subsection{CorrelationCoefficient.java}
\begin{lstlisting}
package hw2.widrowhoff;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;

public class CorrelationCoefficient {

	public static List<Pair<String,Double>> calculate(final DataSet dataSet, final List<Double> classifications ) {
		final String[] labels = dataSet.fields;
		List<Pair<String,Double>> coefficients = new ArrayList<Pair<String,Double>>();
		
		final List<List<Double>> transformedArray = transform(dataSet.exData);
		final double classificationMean = mean(classifications);
		
		int i = 0;
		for( final List<Double> array : transformedArray ) {
			final double mean = mean(array);
			final String label = labels[i];
			
			double numeratorSum = 0.0;
			double xDenominatorSum = 0.0;
			double yDenominatorSum = 0.0;
			
			int j = 0;
			for( final Double x : array ) {
				final double xDiff = x - mean;
				final double yDiff = classifications.get(j) - classificationMean;
				
				numeratorSum += xDiff * yDiff;
				xDenominatorSum += xDiff * xDiff;
				yDenominatorSum += yDiff * yDiff;
				
				j++;
			}
			
			final Double correlationCoefficient = numeratorSum / Math.sqrt(xDenominatorSum * yDenominatorSum);
			final Pair<String,Double> coefficientWithLabel = new Pair<String,Double>(label, correlationCoefficient);
			coefficients.add(coefficientWithLabel);
			i++;
		}
		
		return coefficients;
	}
	
	private static List< List<Double> > transform(double[][] data ) {
		List<List<Double>> transformed = new ArrayList<List<Double>>();
		
		for( int i = 0; i < data[0].length; i++ ) {
			List<Double> column = new ArrayList<Double>();
			for( int j = 0; j < data.length; j++ ) {
				column.add(data[j][i]);
			}
			transformed.add(column);
		}
		
		return transformed;
	}
	
	private static double mean(final double[] array) {
		double sum = 0.0;
		for( int i = 0; i < array.length; i++ ) {
			sum+= array[i];
		}
		return sum / (double) array.length;
	}
	
	private static double mean(final List<Double> array) {
		double sum = 0.0;
		for( int i = 0; i < array.size(); i++ ) {
			sum+= array.get(i);
		}
		return sum / (double) array.size();
	}
}
\end{lstlisting}
\subsection{WidrowHoffLearner.java}
\begin{lstlisting}
package hw2.widrowhoff;

import java.util.ArrayList;
import java.util.List;

public class WidrowHoffLearner {

	private double[] weights;
	private double[] homogeneousWeights;
	private double[][] x;
	private double alpha = 1;
	private double threshold;
	private double[] labels;
	private double margin;
	
	public WidrowHoffLearner( final DataSet dataSet, final double[] weights, final double threshold ) {
		this.x = dataSet.exData;
		this.labels = dataSet.exLabels;
		this.threshold = threshold;
	}
	
	public WidrowHoffLearner( final DataSet dataSet, final double threshold ) {
		this.x = dataSet.exData;
		this.labels = dataSet.exLabels;
		final int inputLength = x[0].length; // get input vector length less the value of the class
		double[] weightsVector = new double[inputLength];
		for( int i = 0; i < inputLength; i++ ) {
			weightsVector[i] = 0;
		}
		this.weights = weightsVector;
		
		homogeneousWeights = new double[ weights.length + 1];
		homogeneousWeights[0] = threshold;
		for(int k = 1; k < weights.length; k++ ) {
			homogeneousWeights[k] = weights[k - 1];
		}
		
		this.threshold = threshold;
	}
	
	public void trainWeightVector() {
		int iterations = 0;
		while( true ) {
			int errors = 0;
			for( int i = 0; i < x.length; i++ ) {
				double[] heterogeneousInputs = x[i];
				double[] inputs = new double[heterogeneousInputs.length + 1];
				inputs[0] = -1;
				for(int j = 1; j < inputs.length; j++) {
					inputs[j] = heterogeneousInputs[j-1];
				}
				
				double err = labels[i] - percepW( inputs ); // use last value in array as label
				
				// 0 - correct
				// -1 - false positive
				// 1 - false negative
				if( err != 0.0 ) {
					errors++;
//					double loss = -1.0 * err * VectorUtils.dotProduct(inputs, weights);
					
					final double[] scaledInputs = VectorUtils.scale(inputs, alpha * err );
					homogeneousWeights = VectorUtils.add(scaledInputs, homogeneousWeights);
				}
			}
			
			if(errors == 0) {
				break;
			}
			
			iterations++;
		}
		
		calculateMargin();
		
		for( int i = 1; i < homogeneousWeights.length; i++ ) {
			weights[i-1] = homogeneousWeights[i];
		}
		
		System.out.println("The training took " + iterations + " epochs.");
		System.out.println("Threshhold: " + homogeneousWeights[0]);
		System.out.println("\\( \\gamma \\rightarrow " + margin + " \\)");
	}
	
	public void testWeightVector(DataSet dataSet) {
		int falseNegatives = 0;
		int falsePositives = 0;
		int truePositives = 0;
		int trueNegatives = 0;
		double totalLoss = 0.0;
		for( int i = 0; i < dataSet.exData.length; i++ ) {
			double[] heterogeneousInputs = dataSet.exData[i];
			double[] inputs = new double[heterogeneousInputs.length + 1];
			inputs[0] = -1;
			for(int j = 1; j < inputs.length; j++) {
				inputs[j] = heterogeneousInputs[j-1];
			}
			
			final double percepResult = percepW( inputs );
			final double err = dataSet.exLabels[i] - percepResult; // use last value in array as label
			
			// 0 - correct
			// -1 - false positive
			// 1 - false negative
			if( err > 0.0 ) {
				falseNegatives++;
				System.out.println("False Negative Found: ");
				System.out.println("Index: " + i);
				System.out.println("Inputs: " + vectorToString(inputs));
				totalLoss += -1.0 * err * VectorUtils.dotProduct(inputs, homogeneousWeights);
			} else if ( err < 0.0 ) {
				falsePositives++;
				System.out.println("False Positive Found: ");
				System.out.println("Index: " + i);
				System.out.println("Inputs: " + vectorToString(inputs));
				totalLoss += -1.0 * err * VectorUtils.dotProduct(inputs, homogeneousWeights);
			} else {
				if( percepResult == 1 ) {
					truePositives++;
				} else {
					trueNegatives++;
				}
			}
		}
		
		System.out.println("True Positives: " + truePositives );
		System.out.println("True Negatives: " + trueNegatives );
		System.out.println("False positives: " + falsePositives);
		System.out.println("False negatives: " + falseNegatives);
		System.out.println("Total loss: " + totalLoss);
		System.out.println("Total items: " + dataSet.exData.length );
	}
	
	private String vectorToString( final double[] x ) {
		StringBuilder stringBuilder = new StringBuilder();
		stringBuilder.append("(");
		for( int i = 1; i < x.length; i++ ) {
			stringBuilder.append(x[i]);
			if( i != x.length - 1) {
				stringBuilder.append(", ");
			}
		}
		stringBuilder.append(")");
		return stringBuilder.toString();
	}
	
	public List<Double> applyWeightVector(DataSet dataSet) {
		List<Double> classifications = new ArrayList<Double>();
		for( int i = 0; i < dataSet.exData.length; i++ ) {
			double[] heterogeneousInputs = dataSet.exData[i];
			double[] inputs = new double[heterogeneousInputs.length + 1];
			inputs[0] = -1;
			for(int j = 1; j < inputs.length; j++) {
				inputs[j] = heterogeneousInputs[j-1];
			}
			double classification = percepW(inputs);
			classifications.add(classification);
		}
		return classifications;
	}
	
	private void calculateMargin() {
		margin = Double.MAX_VALUE;
		final double[] unitWeightVector = VectorUtils.unitVector(homogeneousWeights);
		
		for( int i = 0; i < x.length; i++ ) {
			double[] inputs = x[i];
			
			double dotProduct = Math.abs( VectorUtils.dotProduct(unitWeightVector, inputs) );
			double norm = VectorUtils.norm(inputs);
			
			double marginPart = dotProduct / norm;
			
			margin = Math.min(margin, marginPart);
		}
	}
	
	private double percepW( final double[] curInputVector ) {
		double sum = 0.0;
		
		sum += VectorUtils.dotProduct( curInputVector, homogeneousWeights );
		
		if( sum > 0 ) return 1;
		else if ( sum < 0 ) return 0;
		else return 0;
	}

	public double[] getWeights() {
		return weights;
	}
	public double[][] getX() {
		return x;
	}

	public double getAlpha() {
		return alpha;
	}

	public double getThreshold() {
		return threshold;
	}

	public double[] getLabels() {
		return labels;
	}

	public double getMargin() {
		return margin;
	}

}
\end{lstlisting}
\end{document}

